{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd0vxlyMSCbq"
      },
      "source": [
        "# Making the model (ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0_MAd8Y_DIX",
        "outputId": "de82cba6-5e31-4cd8-86f2-bf203de97574"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"emineyetm/fake-news-detection-datasets\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DZzDBe_LBrbr"
      },
      "outputs": [],
      "source": [
        "path_fake = path+'/News _dataset/Fake.csv'\n",
        "path_real = path+'/News _dataset/True.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f7YdG5__CXfR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W072WIMwCb8r"
      },
      "outputs": [],
      "source": [
        "df_fake = pd.read_csv(path_fake)\n",
        "df_real = pd.read_csv(path_real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cKW58K3CtqC",
        "outputId": "472e3283-250d-469e-a3f3-ff942a8bbd58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lengths of this datasets:\n",
            "Fake: 23481\n",
            "Real: 21417\n"
          ]
        }
      ],
      "source": [
        "print(\"Lengths of this datasets:\")\n",
        "print(\"Fake:\", len(df_fake))\n",
        "print(\"Real:\", len(df_real))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOnE1WILDQVm"
      },
      "source": [
        "# Current approach: Use the entire data set. Train a Naive-Bayes model. (ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BkTb5DRb_kzr"
      },
      "outputs": [],
      "source": [
        "df_fake['label'] = ['Fake' for i in range(len(df_fake))]\n",
        "df_real['label'] = ['Real' for i in range(len(df_real))]\n",
        "df_total = pd.concat([df_fake, df_real])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d4cvXfE1AIvg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df_total['text']\n",
        "y = df_total['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "training_data = pd.DataFrame()\n",
        "training_data['text'] = X_train\n",
        "training_data['label'] = y_train\n",
        "test_data = pd.DataFrame()\n",
        "test_data['text'] = X_test\n",
        "test_data['label'] = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDBFKs4qL3ND",
        "outputId": "cc84dcaf-2a79-445a-d044-6138be357d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('the', 384632), ('to', 228062), ('of', 185759), ('and', 169501), ('a', 162009), ('in', 121691), ('that', 110339), ('s', 101856), ('is', 84173), ('for', 70399)]\n",
            "[('the', 337221), ('to', 194431), ('of', 163017), ('a', 149018), ('and', 142920), ('in', 135237), ('on', 83598), ('that', 65814), ('for', 61912), ('said', 57525)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "fake_fd = Counter()\n",
        "real_fd = Counter()\n",
        "fake_count = 0\n",
        "real_count = 0\n",
        "\n",
        "for row in training_data.iterrows():\n",
        "  if row[1]['label'] == 'Fake': # For whatever reason all the info is in row[1]\n",
        "    fake_count += 1\n",
        "    for word in row[1]['text'].split():\n",
        "      fake_fd[word] += 1\n",
        "  if row[1]['label'] == 'Real':\n",
        "    real_count += 1\n",
        "    for word in row[1]['text'].split():\n",
        "      real_fd[word] += 1\n",
        "\n",
        "print(fake_fd.most_common(10))\n",
        "print(real_fd.most_common(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghno0AoGN5dZ",
        "outputId": "f5f412c6-2dd6-4132-b77b-825f2d637c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5239155855003063\n",
            "0.47608441449969374\n"
          ]
        }
      ],
      "source": [
        "# prior probabilities\n",
        "fake_prior = fake_count / (len(training_data))\n",
        "real_prior = real_count / (len(training_data))\n",
        "\n",
        "print(fake_prior)\n",
        "print(real_prior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNqJlBNFOBwp",
        "outputId": "355370e3-22be-4c29-a71f-d4ebc4c74d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 0.9804008908685968\n"
          ]
        }
      ],
      "source": [
        "from math import log\n",
        "\n",
        "# Prepares for iterations\n",
        "real_total = real_fd.total()\n",
        "fake_total = fake_fd.total()\n",
        "predicted_real = 0\n",
        "predicted_fake = 0\n",
        "predictions = []\n",
        "\n",
        "# Loops through each review in the development data\n",
        "for row in test_data.iterrows():\n",
        "\n",
        "  # Uses log of prior score as base probability\n",
        "  fake_score = log(fake_prior)\n",
        "  real_score = log(real_prior)\n",
        "\n",
        "  # Loops through each word in the development data, computing it's real and fake score. (With log probabilities)\n",
        "  for word in row[1]['text'].split():\n",
        "\n",
        "    # Add-one smoothing implementation for positive\n",
        "    if real_fd[word] == 0:\n",
        "      real_score += log((real_fd[word]+1)/(real_total+len(real_fd)))\n",
        "    else:\n",
        "      real_score += log(real_fd[word]/real_total)\n",
        "\n",
        "    # Add-one smoothing implementation for negative\n",
        "    if fake_fd[word] == 0:\n",
        "      fake_score += log((fake_fd[word]+1)/(fake_total+len(fake_fd)))\n",
        "    else:\n",
        "      fake_score += log(fake_fd[word]/fake_total)\n",
        "\n",
        "  # Predicts label\n",
        "  predicted_label = 'Real'\n",
        "  if fake_score > real_score:\n",
        "    predicted_label = 'Fake'\n",
        "    predicted_fake += 1\n",
        "  else:\n",
        "    predicted_real += 1\n",
        "\n",
        "  # Appends to\n",
        "  predictions.append(predicted_label)\n",
        "\n",
        "# Compute accuracy\n",
        "true_prediction = 0\n",
        "for prediction, row in zip(predictions, test_data.iterrows()):\n",
        "  if prediction == row[1]['label']:\n",
        "    true_prediction += 1\n",
        "accuracy = true_prediction / len(test_data)\n",
        "\n",
        "# Print the model accuracy\n",
        "print(\"Model Accuracy: \" + str(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BiqxXLSAQvOb"
      },
      "outputs": [],
      "source": [
        "# Save current dataset\n",
        "training_data.to_csv('training_data.csv')\n",
        "test_data.to_csv('test_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN-35IdlSIMp"
      },
      "source": [
        "# Loading the model (ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DMwKxrhVR-yv"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from math import log\n",
        "import math\n",
        "\n",
        "# Load datasets\n",
        "class FakeNewsDataset():\n",
        "  def __init__(self, train_path, test_path):\n",
        "    self.train_data = pd.read_csv(train_path)\n",
        "    self.test_data = pd.read_csv(test_path)\n",
        "    self.data = pd.concat([self.train_data, self.test_data])\n",
        "    print(f\"Initialized dataset: {len(self.data)}\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]\n",
        "\n",
        "# Naive-Bayes Model\n",
        "class NaiveBayes():\n",
        "  def __init__(self, dataset: FakeNewsDataset):\n",
        "\n",
        "    # Initialize dataset. NOTE: Must be FakeNewsDataset structure\n",
        "    self.dataset = dataset\n",
        "\n",
        "    # Initialize prior variables\n",
        "    self.fake_fd = Counter()\n",
        "    self.real_fd = Counter()\n",
        "    self.fake_prior = 0\n",
        "    self.real_prior = 0\n",
        "    fake_count = 0\n",
        "    real_count = 0\n",
        "    for row in self.dataset.train_data.iterrows():\n",
        "      if row[1]['label'] == 'Fake': # For whatever reason all the info is in row[1]\n",
        "        fake_count += 1\n",
        "        for word in row[1]['text'].split():\n",
        "          self.fake_fd[word] += 1\n",
        "      if row[1]['label'] == 'Real':\n",
        "        real_count += 1\n",
        "        for word in row[1]['text'].split():\n",
        "          self.real_fd[word] += 1\n",
        "    self.fake_prior = fake_count / (len(self.dataset.train_data))\n",
        "    self.real_prior = real_count / (len(self.dataset.train_data))\n",
        "\n",
        "    # Test the model\n",
        "    self.real_total = self.real_fd.total()\n",
        "    self.fake_total = self.fake_fd.total()\n",
        "    predictions = []\n",
        "\n",
        "    # Loops through each review in the development data\n",
        "    for row in self.dataset.test_data.iterrows():\n",
        "\n",
        "      # Predict\n",
        "      predicted_label, real_score, fake_score = self.predict(row[1]['text'])\n",
        "\n",
        "      # Appends to\n",
        "      predictions.append(predicted_label)\n",
        "\n",
        "    # Compute accuracy\n",
        "    true_prediction = 0\n",
        "    for prediction, row in zip(predictions, self.dataset.test_data.iterrows()):\n",
        "      if prediction == row[1]['label']:\n",
        "        true_prediction += 1\n",
        "    self.accuracy = (true_prediction / len(self.dataset.test_data)) * 100\n",
        "    print(f\"Initialized Naive-Bayes model with {self.accuracy:.2f} accuracy\")\n",
        "\n",
        "  def predict(self, text):\n",
        "\n",
        "    # Uses log of prior score as base probability\n",
        "    fake_score = log(self.fake_prior)\n",
        "    real_score = log(self.real_prior)\n",
        "\n",
        "    # Loops through each word in the development data, computing it's real and fake score. (With log probabilities)\n",
        "    for word in text.split():\n",
        "\n",
        "      # Add-one smoothing implementation for positive\n",
        "      if self.real_fd[word] == 0:\n",
        "        real_score += log((self.real_fd[word]+1)/(self.real_total+len(self.real_fd)))\n",
        "      else:\n",
        "        real_score += log(self.real_fd[word]/self.real_total)\n",
        "\n",
        "      # Add-one smoothing implementation for negative\n",
        "      if self.fake_fd[word] == 0:\n",
        "        fake_score += log((self.fake_fd[word]+1)/(self.fake_total+len(self.fake_fd)))\n",
        "      else:\n",
        "        fake_score += log(self.fake_fd[word]/self.fake_total)\n",
        "\n",
        "    # Choose which label to predict\n",
        "    predicted_label = 'Real'\n",
        "    if fake_score > real_score:\n",
        "      predicted_label = 'Fake'\n",
        "    return predicted_label, real_score, fake_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwcbYxJjY6oJ"
      },
      "source": [
        "Using the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuObjQ8DU_o2",
        "outputId": "03472fca-38d1-4676-ad41-ff7d2d605a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized Naive-Bayes model with 98.04 accuracy\n"
          ]
        }
      ],
      "source": [
        "model = NaiveBayes(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5eTAIJlaZxyC"
      },
      "outputs": [],
      "source": [
        "# Examples from the same dataset\n",
        "real_example = \"PARIS (Reuters) - The prospect Donald Trump could become president of the United States is â€œa big worry,â€ Alain Juppe, the pollsters favorite to become President of France next year, was quoted as saying on Wednesday. â€œI donâ€™t know Mr Trump, but thereâ€™s a question mark and a big worry,â€ Juppe, who hopes to be the main candidate of the countryâ€™s center right in Aprilâ€™s presidential elections, told the magazine Paris Match. â€œHis total ignorance of Europe, his disdain for France, his isolationist and protectionist points of view, his outrageous simplifications, his constant changes of tack, are a real concern. But it is for the people of the United States to choose.â€ Trump is the Republican Party candidate for the U.S. presidential elections on Nov. 8.\"\n",
        "fake_example = \"This racist literally committed the hate crime in the name of Donald Trump.On Saturday morning, Khondoker Usama and his friend were getting gas for their vehicle at a Kwik Shop in Wichita, Kansas when they saw a white man hurling obscenities at a black man. Upon seeing Usama and his friend, the man focused on them. Then suddenly it turned onto us, calling us  brown trash, go home. Trump will win,  Usama recalled. You want to live in this country, you better leave,  the man warned Usama and his friend, who is Hispanic.Usama stood up to the bully and told him,  This is my country; who are you to tell me that? That s when the white man became violent, according to the Wichita Eagle.The exchange was heated, Usama said, and he tried to defuse the situation, but his friend got punched and taken to the ground. He said he tried to get between the attacker and his friend but then was pushed himself. He thought he saw the attacker reaching for his pocket and feared he had a weapon, he said, so he backed away and called 911. He kept kicking the student who was laying on the ground,  Usama said.  He was kicking him; it was a gut-wrenching scene. He saw that I was calling the police and got back on his motorcycle and circled around us and was saying  Trump, Trump, Trump, we will make America great again. You losers will be thrown out of the wall. Usama says he didn t know the man who attacked him and his friend, but he also doesn t  know why anyone would do anything so hateful and so wrong to any individual. This isn t the first time a Trump supporter has physically assaulted a person of color, although many of the incidents usually occur at Trump rallies.In North Carolina last week, a white Trump supporter sucker-punched a black man being led out of the rally by security. At the same rally, another white Trump supporter slapped a back man and yelled obscenities at him.And Trump rallies in St. Louis and Chicago nearly turned into race wars as white supporters hurled obscenities, racial epithets, and threats of violence towards protesters. Some protesters were even assaulted. Yet Donald Trump claims no one has gotten hurt at his rallies and he has called for more violence.As for Usama, he urged others to speak up if they find themselves being verbally or physically assaulted. There may be other people who are fearing the same thing. So this is really important in the times we are in, the challenges we are facing as minorities in this country; we better get united and we better speak up. Make no mistake, Donald Trump and the Republican Party are responsible for these racists and their actions. His white supporters literally think they are entitled to be assholes toward minorities and Trump only makes them feel bulletproof and immune to prosecution because he has said he would pay for their legal defense if they get arrested for assault or hate crimes.If Trump becomes president, this is what his America will look like. An America where white racists have free reign to harass and attack people of color at will because they have the blessing of the White House to do so. That s a scary and dangerous America to live in. Featured image via YouTube\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHe0VQqVW0L_",
        "outputId": "9a212827-1610-4877-f1f5-cfd0b922ca59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Fake\n",
            " Real: -18.38230571356164\n",
            " Fake: -17.493687387107165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict result.\n",
        "# Note: Log probabilities means that the greater number\n",
        "# will be chosen. (i.e. closer to 0)\n",
        "prediction, real_score, fake_score = model.predict(\"Trump is president\")\n",
        "print(f\"Prediction: {prediction}\\n Real: {real_score}\\n Fake: {fake_score}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Xpju0-b01j"
      },
      "source": [
        "Another approach: The previous Naive-Bayes classifier classifies best on the level of documents. Let's see how well it does on the level of sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awYnRNbjcgK_",
        "outputId": "b3527be7-ec0d-4de0-92d0-b6bf7f256864"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package mock_corpus to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mock_corpus.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('all') # or specific packages like 'punkt', 'wordnet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuxUgjB24560"
      },
      "source": [
        "# Final Model & Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kagglgehub\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_dBHw_u9cLzM"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from math import log\n",
        "import math\n",
        "import nltk\n",
        "import kagglehub\n",
        "\n",
        "# Load datasets (pre-existing)\n",
        "class FakeNewsDataset():\n",
        "  def __init__(self, train_path, test_path):\n",
        "    self.train_data = pd.read_csv(train_path)\n",
        "    self.test_data = pd.read_csv(test_path)\n",
        "    self.data = pd.concat([self.train_data, self.test_data])\n",
        "    print(f\"Initialized dataset: {len(self.data)}\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "# Load dataset (through kaggle)\n",
        "class FakeNewsDatasetKaggle(FakeNewsDataset):\n",
        "  def __init__(self):\n",
        "\n",
        "    # Download latest version\n",
        "    path = kagglehub.dataset_download(\"emineyetm/fake-news-detection-datasets\")\n",
        "    path_real = path+'/News _dataset/True.csv'\n",
        "    path_fake = path+'/News _dataset/Fake.csv'\n",
        "\n",
        "    # Shape the data into our desired format\n",
        "    df_fake = pd.read_csv(path_fake)\n",
        "    df_real = pd.read_csv(path_real)\n",
        "    df_fake['label'] = ['Fake' for i in range(len(df_fake))]\n",
        "    df_real['label'] = ['Real' for i in range(len(df_real))]\n",
        "\n",
        "    # Split the data into 80/20 train-test\n",
        "    df_total = pd.concat([df_fake, df_real])\n",
        "    self.train_data, self.test_data = train_test_split(df_total, test_size=0.2)\n",
        "    self.data = pd.concat([self.train_data, self.test_data])\n",
        "    print(f\"Initialized dataset: {len(self.data)}\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "# Naive-Bayes Model\n",
        "class NaiveBayes():\n",
        "  def __init__(self, dataset: FakeNewsDataset, unit='article'):\n",
        "\n",
        "    # Initialize dataset. NOTE: Must be FakeNewsDataset structure\n",
        "    self.dataset = dataset\n",
        "\n",
        "    # Initialize prior variables\n",
        "    self.fake_fd = Counter()\n",
        "    self.real_fd = Counter()\n",
        "    self.fake_prior = 0\n",
        "    self.real_prior = 0\n",
        "    fake_count = 0\n",
        "    real_count = 0\n",
        "    total_count = 0\n",
        "    for row in self.dataset.train_data.iterrows():\n",
        "      if row[1]['label'] == 'Fake': # For whatever reason all the info is in row[1]\n",
        "        fake_count += 1\n",
        "        total_count += 1\n",
        "        for word in row[1]['text'].split():\n",
        "          self.fake_fd[word] += 1\n",
        "      if row[1]['label'] == 'Real':\n",
        "        real_count += 1\n",
        "        total_count += 1\n",
        "        for word in row[1]['text'].split():\n",
        "          self.real_fd[word] += 1\n",
        "    self.fake_prior = fake_count / total_count\n",
        "    self.real_prior = real_count / total_count\n",
        "\n",
        "    # Test the model\n",
        "    self.real_total = self.real_fd.total()\n",
        "    self.fake_total = self.fake_fd.total()\n",
        "    predictions = []\n",
        "\n",
        "    # Loops through each review in the development data\n",
        "    for row in self.dataset.test_data.iterrows():\n",
        "\n",
        "      # Handles articles\n",
        "      if unit=='article':\n",
        "\n",
        "        # Predict\n",
        "        predicted_label, real_score, fake_score = self.predict(row[1]['text'])\n",
        "\n",
        "        # Appends to\n",
        "        predictions.append(predicted_label)\n",
        "\n",
        "      # Handles sentences\n",
        "      elif unit=='sentence':\n",
        "\n",
        "        # Split into sentences\n",
        "        sentences = nltk.sent_tokenize(row[1]['text'])\n",
        "\n",
        "        # Iterate through each sentence\n",
        "        sentence_predictions = []\n",
        "        for sentence in sentences:\n",
        "\n",
        "          # Predict\n",
        "          predicted_label, real_score, fake_score = self.predict(sentence)\n",
        "\n",
        "          # Appends to current sentence prediction\n",
        "          sentence_predictions.append(predicted_label)\n",
        "\n",
        "        # Append onto final prediction\n",
        "        predictions.append(sentence_predictions)\n",
        "\n",
        "\n",
        "    # Compute accuracy of article prediction\n",
        "    if unit=='article':\n",
        "      true_prediction = 0\n",
        "      for prediction, row in zip(predictions, self.dataset.test_data.iterrows()):\n",
        "        if prediction == row[1]['label']:\n",
        "          true_prediction += 1\n",
        "      self.accuracy = (true_prediction / len(self.dataset.test_data)) * 100\n",
        "\n",
        "    # Compute accuracy of sentence prediction\n",
        "    elif unit=='sentence':\n",
        "      true_prediction = 0\n",
        "      total_sentences = 0\n",
        "      for prediction, row in zip(predictions, self.dataset.test_data.iterrows()):\n",
        "        answer = row[1]['label']\n",
        "        for pred in prediction:\n",
        "          total_sentences += 1\n",
        "          if pred == answer:\n",
        "            true_prediction += 1\n",
        "      self.accuracy = (true_prediction / total_sentences) * 100\n",
        "\n",
        "    # Done\n",
        "    print(f\"Initialized Naive-Bayes model with {self.accuracy:.2f} accuracy\")\n",
        "\n",
        "  def predict(self, text):\n",
        "\n",
        "    # Uses log of prior score as base probability\n",
        "    fake_score = log(self.fake_prior)\n",
        "    real_score = log(self.real_prior)\n",
        "\n",
        "    # Loops through each word in the development data, computing it's real and fake score. (With log probabilities)\n",
        "    for word in text.split():\n",
        "\n",
        "      # Add-one smoothing implementation for positive\n",
        "      if self.real_fd[word] == 0:\n",
        "        real_score += log((self.real_fd[word]+1)/(self.real_total+len(self.real_fd)))\n",
        "      else:\n",
        "        real_score += log(self.real_fd[word]/self.real_total)\n",
        "\n",
        "      # Add-one smoothing implementation for negative\n",
        "      if self.fake_fd[word] == 0:\n",
        "        fake_score += log((self.fake_fd[word]+1)/(self.fake_total+len(self.fake_fd)))\n",
        "      else:\n",
        "        fake_score += log(self.fake_fd[word]/self.fake_total)\n",
        "\n",
        "    # Choose which label to predict\n",
        "    predicted_label = 'Real'\n",
        "    if fake_score > real_score:\n",
        "      predicted_label = 'Fake'\n",
        "    return predicted_label, real_score, fake_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH3IVCi6j6eC",
        "outputId": "625fbe69-998e-4f0c-86ae-6772d1664c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset: 44898\n",
            "Initialized Naive-Bayes model with 98.10 accuracy\n"
          ]
        }
      ],
      "source": [
        "dataset = FakeNewsDatasetKaggle()\n",
        "model = NaiveBayes(dataset, unit='article')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuaKVfJ35A0f",
        "outputId": "8938dde2-51de-405a-cdd5-eed30b81ea33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Real\n",
            " Real: -39.1225706285355\n",
            " Fake: -39.84096867386622\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict result.\n",
        "# Note: Log probabilities means that the greater number\n",
        "# will be chosen. (i.e. closer to 0)\n",
        "prediction, real_score, fake_score = model.predict(\"We the people of the United States.\")\n",
        "print(f\"Prediction: {prediction}\\n Real: {real_score}\\n Fake: {fake_score}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH66fP7q5-0D"
      },
      "source": [
        "Conclusion: This model probably can't detect fake news as accurately because it doesn't have knowledge of the real world. However, it's pretty capable of detecting real news from fake news based off of the probabilities within the text. Therefore, due to this model's fast prediction speed, it's probably best to use this as a secondary source.\n",
        "\n",
        "\n",
        "A potential pipeline could be:\n",
        "\n",
        "\n",
        "1.   Naive Bayes flags a sentences as fake news.\n",
        "2.   Another check is done by another model.\n",
        "3.   A final check is done by checking if the sentence has any reputable sources.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
